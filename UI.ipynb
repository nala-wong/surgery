{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tkinter import Tk, ttk, StringVar, Label, Entry, Button, Text, filedialog, END, W, E, N\n",
    "from tkinter import *\n",
    "from tkinter import Tk, ttk, StringVar, Label, Entry, Button, Text, filedialog, END, W, E, N\n",
    "import cv2\n",
    "import os\n",
    "from PIL import ImageTk, Image\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "#from object_detection.utils import visualization_utils as vis_util\n",
    "    \n",
    "\n",
    "################################################################################################\n",
    "# Parameters\n",
    "################################################################################################\n",
    "MODEL_NAME = os.getcwd()\n",
    "LABEL_PATH = os.path.join(MODEL_NAME, 'data')\n",
    "PATH_TO_CKPT = os.path.join(MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "PATH_TO_LABELS = os.path.join(LABEL_PATH, 'surgery_label_displayname_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 15\n",
    "MIN_CONFIDENCE_LEVEL = 0.7\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# Global Variables\n",
    "################################################################################################\n",
    "detection_graph = None   # to store detection model\n",
    "category_names = None    # to store class name mapping\n",
    "category_descs = None     # to store class desc. (display name) mapping\n",
    "\n",
    "    \n",
    "def cropping_new_images(test_images_paths, photo_num, coordinates , width, height):\n",
    "    image = cv2.imread(test_images_paths)\n",
    "#     ymin = math.ceil(coordinates[0] * ratio[0])\n",
    "#     xmin = math.ceil(coordinates[1] * ratio[1])\n",
    "#     ymax = math.ceil(coordinates[2] * ratio[0])\n",
    "#     xmax = math.ceil(coordinates[3] * ratio[1])\n",
    "#     ymin = ymin - 5\n",
    "#     xmin = xmin - 5\n",
    "#     xmax = xmax + 5\n",
    "#     ymax = ymax + 5\n",
    "    ymin = coordinates[0]\n",
    "    xmin = coordinates[1]\n",
    "    ymax = coordinates[2] \n",
    "    xmax = coordinates[3]\n",
    "    _, tail = os.path.split(test_images_paths)\n",
    "#     cropped_image = tf.image.crop_to_bounding_box(image, ymin, xmin, ymax - ymin, xmax - xmin)\n",
    "#     output_image = tf.image.encode_png(cropped_image)\n",
    "    output_image=image[ymin:ymax, xmin:xmax]\n",
    "    file_name = os.path.join('surgery_data', tail.replace('.jpg', '_' + 'new_' + str(photo_num) + '.jpg'))\n",
    "    cv2.imwrite(file_name, cv2.resize(output_image,(width, height)))\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# align the detected image with original image\n",
    "################################################################################################\n",
    "def alignImage(original_image_path, detect_image_path):\n",
    "    MIN_MATCH_COUNT = 4\n",
    "\n",
    "    imgname2 = original_image_path\n",
    "    imgname1 = detect_image_path\n",
    "\n",
    "    img1 = cv2.imread(imgname1)\n",
    "    img2 = cv2.imread(imgname2)\n",
    "    h, w, _ = img1.shape\n",
    "    h1, w1, _ = img2.shape\n",
    "    if h1 >= h:\n",
    "        h = h1\n",
    "    if w1 > w:\n",
    "        w = w1\n",
    "    height = (math.floor(h / 10) + 1) * 10\n",
    "    width = (math.floor(w / 10) + 1) * 10\n",
    "    img1 = cv2.resize(img1, (width, height))\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # # (3) Create flann matcher\n",
    "    matcher = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), {})\n",
    "\n",
    "    # # (4) Detect keypoints and compute keypointer descriptors\n",
    "    kpts1, descs1 = sift.detectAndCompute(gray1, None)\n",
    "    kpts2, descs2 = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "    # # (5) knnMatch to get Top2\n",
    "    matches = matcher.knnMatch(descs1, descs2, 2)\n",
    "    # Sort by their distance.\n",
    "    matches = sorted(matches, key=lambda x:x[0].distance)\n",
    "\n",
    "    # # (6) Ratio test, to get good matches.\n",
    "    good = [m1 for (m1, m2) in matches if m1.distance < 0.7 * m2.distance]\n",
    "\n",
    "    canvas = img2.copy()\n",
    "\n",
    "    # # (7) find homography matrix\n",
    "    if len(good) > MIN_MATCH_COUNT:\n",
    "        # # (queryIndex for the small object, trainIndex for the scene )\n",
    "        src_pts = np.float32([ kpts1[m.queryIdx].pt for m in good ]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([ kpts2[m.trainIdx].pt for m in good ]).reshape(-1, 1, 2)\n",
    "        # # find homography matrix in cv2.RANSAC using good match points\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        # matchesMask2 = mask.ravel().tolist()\n",
    "        h, w = img1.shape[:2]\n",
    "        pts = np.float32([ [0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0] ]).reshape(-1, 1, 2)\n",
    "        dst = cv2.perspectiveTransform(pts, M)\n",
    "        # # 绘制边框\n",
    "        cv2.polylines(canvas, [np.int32(dst)], True, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "    else:\n",
    "        print(\"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT))\n",
    "\n",
    "    # # (8) drawMatches\n",
    "    matched = cv2.drawMatches(img1, kpts1, canvas, kpts2, good, None)  # ,**draw_params)\n",
    "\n",
    "    # # (9) Crop the matched region from scene\n",
    "    h, w = img1.shape[:2]\n",
    "    pts = np.float32([ [0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0] ]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "    perspectiveM = cv2.getPerspectiveTransform(np.float32(dst), pts)\n",
    "    found = cv2.warpPerspective(img2, perspectiveM, (w, h))\n",
    "    return found\n",
    "\n",
    "\n",
    "def difference_detection_program(original_images_path, after_surgery_img2_path, photo_number_name, final_file_location=[]):\n",
    "    \n",
    "    found = alignImage(original_images_path, after_surgery_img2_path)\n",
    "    height, width = found.shape[:2]\n",
    "    newW = width + 10\n",
    "    newH = height + 10 \n",
    "    found = cv2.resize(found, (newW, newH))\n",
    "    im1 = cv2.imread(after_surgery_img2_path)\n",
    "    im = cv2.resize(found, (width, height))\n",
    "    im1 = cv2.resize(im1, (width, height))\n",
    "    diff = cv2.subtract(im, im1)\n",
    "    im = cv2.resize(diff, (width, height))\n",
    "    imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(imgray, 120, 180, 0)\n",
    "    _, contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(im1, contours, -1, (127, 255, 0), 4)\n",
    "    final_file_names = 'final_result_' +  str(photo_number_name) + \".jpg\"\n",
    "    \n",
    "    cv2.imwrite(final_file_names, im1)\n",
    "    final_file_location.append(final_file_names) \n",
    "\n",
    "\n",
    "def highlighting_brown_color(panel3,images_path):\n",
    "    image123 = cv2.imread(images_path,cv2.IMREAD_UNCHANGED)\n",
    "    #inRange(hsv, Scalar(0, 100, 20), Scalar(10, 255, 255), mask1);\n",
    "    #inRange(hsv, Scalar(170, 100, 20), Scalar(180, 255, 255), mask2);\n",
    "    red = np.array([0, 140, 20])\n",
    "    red1 = np.array([10, 255, 255])\n",
    "    red2 = np.array([170, 100, 20])\n",
    "    red3 = np.array([180, 250, 250])\n",
    "    #red4 = np.array([3, 100, 20])\n",
    "    #red5 = np.array([20, 255, 200])\n",
    "    hsv = cv2.cvtColor(image123, cv2.COLOR_BGR2HSV)\n",
    "    mask1 = cv2.inRange(hsv, red, red1)\n",
    "    mask2 = cv2.inRange(hsv, red2, red3)\n",
    "    #mask3 = cv2.inRange(hsv, red4, red5)\n",
    "    mask = mask1 + mask2 #+ mask3\n",
    "    ret, thresh = cv2.threshold(mask, 0, 255, 0)\n",
    "    _, contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(image123, contours, -1, (127, 255, 0), 1)\n",
    "    \n",
    "    filename = 'final.jpg'\n",
    "    cv2.drawContours(image123, contours, -1, (127, 255, 0), 2)\n",
    "    cv2.imwrite(filename, image123)\n",
    "    img = Image.open(filename)\n",
    "    img = img.resize((400,400))\n",
    "    # resize the final image to be displayed\n",
    "    #ratio_h = panel_h / maxH\n",
    "    #ratio_w = panel_w / total_width\n",
    "    #ratio_min = min(ratio_h, ratio_w)\n",
    "    #display_h = int(maxH*ratio_min)\n",
    "    #display_w = int(total_width*ratio_min)\n",
    "    #img = cv2.resize(img,(400,600))\n",
    "    img_resized = ImageTk.PhotoImage(img)\n",
    "    panel3.image = img_resized\n",
    "    panel3.configure(image = img_resized) \n",
    "    \n",
    "    \n",
    "    \n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)  \n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "            \n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict     \n",
    "\n",
    "\n",
    "################################################################################################\n",
    "# Load Object Detection Model\n",
    "################################################################################################\n",
    "def load_model(modelFilePath):\n",
    "   \n",
    "    # load model\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(modelFilePath, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "    return detection_graph\n",
    "\n",
    "  \n",
    "################################################################################################\n",
    "# Load Object Detection Label\n",
    "################################################################################################  \n",
    "def load_label(label_file_path, num_classes, use_display_name=True):\n",
    "    label_map = label_map_util.load_labelmap(label_file_path)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=use_display_name)\n",
    "    category_index = label_map_util.create_category_index(categories)  \n",
    "    return category_index;\n",
    "    \n",
    "    \n",
    "def detection_surgery(test_images_paths, photo_num, result_output1, file_path_to_extarcted_one=[], file_path_to_after=[], final_file_location=[]):\n",
    "    global detection_graph\n",
    "    global category_names\n",
    "    global category_descs\n",
    "\n",
    "    image = Image.open(test_images_paths)\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "#     image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "\n",
    "    head, tail = os.path.split(test_images_paths)\n",
    "    boxes = output_dict['detection_boxes']\n",
    "    scores = output_dict['detection_scores']\n",
    "    classes = output_dict['detection_classes']\n",
    "    boxes_shape = boxes.shape\n",
    "    im_width, im_height = image.size\n",
    "    frequency = [0] * NUM_CLASSES\n",
    "    tot = 0 # number of class detected\n",
    "    \n",
    "    eq_list = [-1] * 100\n",
    "    \n",
    "    # Detection Part\n",
    "    for i in range(boxes_shape[0]):\n",
    "        if (scores[i] > MIN_CONFIDENCE_LEVEL):\n",
    "            ymin = int(boxes[i, 0] * im_height)\n",
    "            xmin = int(boxes[i, 1] * im_width)\n",
    "            ymax = int(boxes[i, 2] * im_height)\n",
    "            xmax = int(boxes[i, 3] * im_width)\n",
    "            coordinate_of_object = []\n",
    "            #ratio_to_the_original = []\n",
    "            # +/ - of y and x max/min value here is to give extra space in the image in order to avoid cases which some part of the object were cropped out\n",
    "            coordinate_of_object.append(ymin - 10)\n",
    "            coordinate_of_object.append(xmin - 10)\n",
    "            coordinate_of_object.append(ymax)\n",
    "            coordinate_of_object.append(xmax + 10)\n",
    "            #file_path_to_original = os.path.join(os.getcwd(), 'original', classes[i])\n",
    "            file_name_original = os.path.join('original', str(output_dict['detection_classes'][i]) + '.jpg')\n",
    "            im = Image.open(file_name_original)\n",
    "            w, h = im.size\n",
    "#             ratio_to_the_original.append(float(h / im_height))\n",
    "#             ratio_to_the_original.append(float(w / im_width))\n",
    "            cropping_new_images(test_images_paths, classes[i], coordinate_of_object, w, h)\n",
    "            eq_list[tot] = classes[i]  # store class id \n",
    "            tot += 1\n",
    "            frequency[i] += 1\n",
    "            file_name = os.path.join('surgery_data', tail.replace('.jpg', '_' + 'new_' + str(classes[i]) + '.jpg'))\n",
    "            \n",
    "#             if photo_num % 2 != 0:\n",
    "#                 file_name = os.path.join(os.getcwd(), file_name)\n",
    "#                 file_path_to_extarcted_one.append(file_name)  # getting original image that used for comparison\n",
    "            if photo_num % 2 == 0:\n",
    "                file_name = os.path.join(os.getcwd(), file_name)\n",
    "                file_path_to_after.append(file_name) \n",
    "                file_path_to_extarcted_one.append(file_name_original)\n",
    "            \n",
    "#     boxes = output_dict['detection_boxes']\n",
    "#     scores = output_dict['detection_scores']\n",
    "#     boxes_shape = boxes.shape\n",
    "    tot = 0 \n",
    "    class_name = ''\n",
    "    model_numbers = []\n",
    "    quantity_of_models = []\n",
    "    description_of_models = []\n",
    "    des_model_num = ''\n",
    "    \n",
    "    # loop for each class and append the result if count > 0\n",
    "    for i in range(1, NUM_CLASSES+1):\n",
    "        \n",
    "        if eq_list.count(i) > 0:\n",
    "            \n",
    "            class_name = category_names[i]['name']\n",
    "            des_model_num = category_descs[i]['name']\n",
    "            model_numbers.append(class_name)\n",
    "            quantity_of_models.append(str(eq_list.count(i)))\n",
    "            description_of_models.append(des_model_num)\n",
    "#     if photo_num % 2 != 0:\n",
    "#         result_output.insert(END, 'Detection Result from before of the Surgery ' + '\\n' + '\\n')\n",
    "#         result_output.insert(END, 'Model Number  ' + 'Description                      ' + 'Qty' + '\\n')\n",
    "    if photo_num % 2 == 0:\n",
    "        #result_output1.insert(END, 'Detection Result ' + '\\n' )\n",
    "        result_output1.delete(1.0, END)\n",
    "        result_output1.insert(END, 'Qty   ' + ' Model ' + '\\n')\n",
    "        result_output1.insert(END, '------' + ' ---------------------------------------------------------------' + '\\n')\n",
    "    for i, j, k in zip(model_numbers, description_of_models, quantity_of_models):\n",
    "        if photo_num % 2 == 0:\n",
    "            result_output1.insert(END, k.ljust(6) + ' ' + i + ' (' + j + ')\\n')\n",
    "#         else:\n",
    "#             result_output.insert(END, i + '  ' + j + '   ' + k + '\\n')\n",
    "    '''\n",
    "    if photo_num % 2 == 0:\n",
    "        tot_photo_count = 0\n",
    "\n",
    "        for x, y in zip(file_path_to_extarcted_one, file_path_to_after):\n",
    "            #difference_detection_program(x, y, tot_photo_count, final_file_location)\n",
    "            highlighting_brown_color(x,y, tot_photo_count, final_file_location)\n",
    "            tot_photo_count += 1\n",
    "    '''\n",
    "    \n",
    "#########################################################################    \n",
    "# function to combine image list to 1 image\n",
    "#########################################################################        \n",
    "def combine_all_together(panel3, final_image_list=[]):\n",
    "    loaded_images = []\n",
    "    # panel size\n",
    "    panel_h = panel3.winfo_height()\n",
    "    panel_w = panel3.winfo_width()\n",
    "   \n",
    "    # to calculate the final image size\n",
    "    maxH = 0\n",
    "    total_width = 0\n",
    "    for x in final_image_list:\n",
    "        img = cv2.imread(x)\n",
    "        h, w = img.shape[:2]\n",
    "        maxH = max(h, maxH)\n",
    "        total_width += w\n",
    "        \n",
    "    # combine all images to final image    \n",
    "    for x in final_image_list:\n",
    "        img = cv2.imread(x)\n",
    "        h, w = img.shape[:2]\n",
    "        data = np.zeros((maxH,w,3), dtype= np.uint8)\n",
    "       \n",
    "        data[0:h, 0:w] = img\n",
    "        loaded_images.append(data)\n",
    "    numpy_horizontal = np.hstack(loaded_images)\n",
    "    filename = 'final.jpg'\n",
    "    cv2.imwrite(filename, numpy_horizontal)\n",
    "    img = Image.open(filename)\n",
    "    \n",
    "    # resize the final image to be displayed\n",
    "    ratio_h = panel_h / maxH\n",
    "    ratio_w = panel_w / total_width\n",
    "    ratio_min = min(ratio_h, ratio_w)\n",
    "    display_h = int(maxH*ratio_min)\n",
    "    display_w = int(total_width*ratio_min)\n",
    "    img = img.resize((400, 400))\n",
    "    \n",
    "    img_resized = ImageTk.PhotoImage(img)\n",
    "    panel3.image = img_resized \n",
    "    panel3.configure(image=img_resized) \n",
    " \n",
    "\n",
    "#########################################################################    \n",
    "# function to browse and display image\n",
    "#########################################################################    \n",
    "def browsefunc(filepath, panel,filetypes=None):\n",
    "    \n",
    "    filename =  filedialog.askopenfilename(filetypes=filetypes)\n",
    "    filepath.set(filename)\n",
    "    if (filename):\n",
    "        img = Image.open(filename)\n",
    "        h = panel.winfo_height() \n",
    "        w = panel.winfo_width() \n",
    "        img = img.resize((h, w)) \n",
    "        img_resized = ImageTk.PhotoImage(img)\n",
    "        panel.image = img_resized \n",
    "        panel.configure(image=img_resized)\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # initial load model and label\n",
    "#     global detection_graph\n",
    "    detection_graph = load_model(PATH_TO_CKPT)\n",
    "#     global category_names\n",
    "    category_names = load_label(PATH_TO_LABELS, NUM_CLASSES, use_display_name=False)\n",
    "#     global category_descs\n",
    "    category_descs = load_label(PATH_TO_LABELS, NUM_CLASSES)  \n",
    "    \n",
    "    root = Tk()  \n",
    "    root.title('Surgery Equipment Detection')\n",
    "#     folder_path1 = StringVar()\n",
    "    folder_path2 = StringVar()\n",
    "#     label1 = Label(root, text=\"Before the Surgery\").grid(row=0, column=0, sticky=W)\n",
    "#     entry1 = Entry(root, width=70, textvariable=folder_path1).grid(row=1, column=0, pady=10)\n",
    "#     browsebutton1 = Button(root, text=\"Browse\", command=lambda:folder_path1.set(filedialog.askopenfilename()))\n",
    "#     browsebutton1.grid(row=0, column=0)\n",
    "#     file = os.path.join(os.getcwd(), 'logo_images', 'b.jpg')\n",
    "#     img1 = ImageTk.PhotoImage(Image.open(file))\n",
    "#     panel1 = Label(root, height=\"400\", width=\"400\", image=img1)\n",
    "#     panel1.grid(row=2, column=0)\n",
    "#     loadbutton1 = Button(root, text=\"Load Image\", command=lambda:browsefunc(folder_path1.get(), panel1))\n",
    "#     loadbutton1.grid(row=0, column=0, sticky=E)\n",
    "    \n",
    "   \n",
    "    # Create a container to hold output message\n",
    "    detectFrame = ttk.LabelFrame(root, text='  1. Object Detection ')\n",
    "    Label(detectFrame, text=\"Select Image file for detection\").grid(row=0, column=1, sticky=W, padx=10)\n",
    "    entry2 = Entry(detectFrame, width=70, textvariable=folder_path2).grid(row=1, column=1, padx=5 , pady=10)\n",
    "    browsebutton2 = Button(detectFrame, text=\"Browse\", command=lambda:browsefunc(folder_path2, panel2,  filetypes=[(\"JPG Files\", \"*.jpg\")]))\n",
    "    browsebutton2.grid(row=1, column=1, padx=5 , pady=10, sticky=E)\n",
    "    \n",
    "    file2 = os.path.join(os.getcwd(), 'logo_images', 'a.jpg')\n",
    "    img2 = ImageTk.PhotoImage(Image.open(file2))\n",
    "    panel2 = Label(detectFrame, height=\"400\", width=\"400\", image=img2)\n",
    "    panel2.grid(row=2, column=1)\n",
    "#     loadbutton2 = Button(root, text=\"Load Image\", command=lambda:browsefunc(folder_path2.get(),panel2))\n",
    "#     loadbutton2.grid(row=0, column=1, sticky=E)\n",
    "    detectFrame.grid(column=1, row=1, pady=5, padx=5)\n",
    "    \n",
    "    \n",
    "    diffFrame = ttk.LabelFrame(root, text=' 2. Check Difference ')\n",
    "    file3 = os.path.join(os.getcwd(), 'logo_images', 'f.jpg')\n",
    "    img3 = ImageTk.PhotoImage(Image.open(file3))\n",
    "    panel3 = Label(diffFrame, height=\"400\", width=\"600\", image=img3)\n",
    "    panel3.grid(row=2, column=3, pady=10)\n",
    "    diffFrame.grid(column=2, row=1, pady=50, padx=5, sticky=N)\n",
    "    \n",
    "    file_path_to_before_surgery = []\n",
    "    file_path_to_after_surgery = []\n",
    "    final_file_locations = []\n",
    "    \n",
    "#     result_output = Text(root, width=50, height=5)\n",
    "#     result_output.grid(row=5, column=0)\n",
    "    scrollbar = Scrollbar(detectFrame)\n",
    "    scrollbar.grid(row = 5, column = 2, sticky=E)\n",
    "    result_output1 = Text(detectFrame, width=70, height=5,yscrollcommand=scrollbar.set)\n",
    "    result_output1.grid(row=5, column=1, padx=5 , pady=5)\n",
    "    scrollbar.config(command=result_output1.yview)\n",
    "#     detectButton1 = Button(root, text=\"DETECT\", command=lambda:detection_surgery(folder_path1.get(), 3, file_path_to_before_surgery, None, final_file_locations)).grid(row=3, column=0)\n",
    "    detectButton2 = Button(detectFrame, text=\"Detect\", command=lambda:detection_surgery(folder_path2.get(), 2, result_output1,file_path_to_before_surgery, file_path_to_after_surgery, final_file_locations), width = 15, bg = \"powder blue\").grid(row=3, column=1)\n",
    "\n",
    "    #defeatCheckButton = Button(diffFrame, text=\"Check for Difference\", command=lambda:combine_all_together(panel3, final_file_locations), bg = \"powder blue\").grid(row=3, column=3, padx=5 , pady=5)\n",
    "    \n",
    "    defeatCheckButton = Button(diffFrame, text=\"Check for Difference\", command=lambda:highlighting_brown_color(panel3, folder_path2.get()), bg = \"powder blue\").grid(row=3, column=3, padx=5 , pady=5)\n",
    "    root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
